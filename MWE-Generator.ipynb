{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc4b81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting WordNet MWEs...\n",
      "WordNet MWEs: 64188\n",
      "Combined raw MWE count: 64188\n",
      "Processed: 5000\n",
      "Processed: 10000\n",
      "Processed: 15000\n",
      "Processed: 20000\n",
      "Processed: 25000\n",
      "Processed: 30000\n",
      "Processed: 35000\n",
      "Processed: 40000\n",
      "Processed: 45000\n",
      "Processed: 50000\n",
      "Processed: 55000\n",
      "Processed: 60000\n",
      "Total output variants (before sorting): 100269\n",
      "Writing to english_mwes_complete.txt ...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from nltk.corpus import wordnet as wn\n",
    "import nltk\n",
    "import spacy\n",
    "import lemminflect\n",
    "import inflect\n",
    "import itertools\n",
    "\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "infl = inflect.engine()\n",
    "\n",
    "OUTPUT = \"mwes.txt\"\n",
    "\n",
    "def extract_wordnet_mwes():\n",
    "    mwes = set()\n",
    "    for syn in wn.all_synsets():\n",
    "        for lemma in syn.lemma_names():\n",
    "            if \"_\" in lemma:\n",
    "                mwes.add(lemma.replace(\"_\", \" \").lower())\n",
    "    return mwes\n",
    "\n",
    "def verb_inflections(lemma):\n",
    "    out = {}\n",
    "    base = lemma\n",
    "    out['VB'] = base\n",
    "\n",
    "    def get(tag):\n",
    "        forms = lemminflect.getInflection(base, tag)\n",
    "        if forms:\n",
    "            return forms[0]\n",
    "        return None\n",
    "\n",
    "    form_vbz = get('VBZ')\n",
    "    if not form_vbz:\n",
    "        if base.endswith('y') and len(base) > 1 and base[-2] not in \"aeiou\":\n",
    "            form_vbz = base[:-1] + \"ies\"\n",
    "        elif base.endswith((\"s\",\"x\",\"z\",\"ch\",\"sh\")):\n",
    "            form_vbz = base + \"es\"\n",
    "        else:\n",
    "            form_vbz = base + \"s\"\n",
    "    out['VBZ'] = form_vbz\n",
    "\n",
    "    form_vbd = get('VBD')\n",
    "    if not form_vbd:\n",
    "        if base.endswith('e'):\n",
    "            form_vbd = base + \"d\"\n",
    "        elif base.endswith('y') and len(base) > 1 and base[-2] not in \"aeiou\":\n",
    "            form_vbd = base[:-1] + \"ied\"\n",
    "        else:\n",
    "            form_vbd = base + \"ed\"\n",
    "    out['VBD'] = form_vbd\n",
    "\n",
    "    form_vbn = get('VBN')\n",
    "    if not form_vbn:\n",
    "        form_vbn = out['VBD']\n",
    "    out['VBN'] = form_vbn\n",
    "\n",
    "    form_vbg = get('VBG')\n",
    "    if not form_vbg:\n",
    "        if base.endswith('ie'):\n",
    "            form_vbg = base[:-2] + \"ying\"\n",
    "        elif base.endswith('e') and not base.endswith('ee'):\n",
    "            form_vbg = base[:-1] + \"ing\"\n",
    "        else:\n",
    "            form_vbg = base + \"ing\"\n",
    "    out['VBG'] = form_vbg\n",
    "\n",
    "    return out\n",
    "\n",
    "def noun_plurals(noun):\n",
    "    p = infl.plural(noun)\n",
    "    return {noun, p} if p and p != noun else {noun}\n",
    "\n",
    "def generate_variants_for_mwe(mwe, max_variants_per_mwe=64):\n",
    "    doc = nlp(mwe)\n",
    "    token_options = []\n",
    "\n",
    "    noun_heads = set()\n",
    "    if all(t.pos_ in (\"NOUN\", \"ADJ\", \"DET\") for t in doc):\n",
    "        for t in doc:\n",
    "            if t.pos_ == \"NOUN\" and t.dep_ == \"ROOT\":\n",
    "                noun_heads.add(t.i)\n",
    "\n",
    "    for i, token in enumerate(doc):\n",
    "        txt = token.text\n",
    "\n",
    "        if token.is_punct or token.is_space:\n",
    "            token_options.append([txt])\n",
    "            continue\n",
    "\n",
    "        if token.tag_ == \"VB\":\n",
    "            lemma = token.lemma_.lower()\n",
    "            infls = verb_inflections(lemma)\n",
    "            opts = [infls['VB'], infls['VBZ'], infls['VBD'], infls['VBN'], infls['VBG']]\n",
    "            seen = []\n",
    "            for o in opts:\n",
    "                if o and o not in seen:\n",
    "                    seen.append(o)\n",
    "            token_options.append(seen)\n",
    "\n",
    "        elif i in noun_heads:\n",
    "            p = infl.plural(token.text.lower())\n",
    "            if p:\n",
    "                token_options.append([token.text.lower(), p])\n",
    "            else:\n",
    "                token_options.append([token.text.lower()])\n",
    "\n",
    "        else:\n",
    "            token_options.append([txt.lower()])\n",
    "\n",
    "    variants = set()\n",
    "    for combo in itertools.product(*token_options):\n",
    "        s = \" \".join([t for t in combo]).strip()\n",
    "        variants.add(s)\n",
    "        if len(variants) >= max_variants_per_mwe:\n",
    "            break\n",
    "    return variants\n",
    "\n",
    "def main():\n",
    "    print(\"Extracting WordNet MWEs...\")\n",
    "    wn_mwes = extract_wordnet_mwes()\n",
    "    print(f\"WordNet MWEs: {len(wn_mwes)}\")\n",
    "\n",
    "    all_mwes = wn_mwes\n",
    "    all_mwes = {m.strip().lower() for m in all_mwes if m.strip()}\n",
    "    print(f\"Combined raw MWE count: {len(all_mwes)}\")\n",
    "\n",
    "    final = set()\n",
    "    count = 0\n",
    "    for m in sorted(all_mwes):\n",
    "        count += 1\n",
    "        if count % 5000 == 0:\n",
    "            print(\"Processed:\", count)\n",
    "        try:\n",
    "            vars_for_m = generate_variants_for_mwe(m)\n",
    "            final.update(vars_for_m)\n",
    "        except Exception:\n",
    "            final.add(m)\n",
    "\n",
    "    print(f\"Total output variants (before sorting): {len(final)}\")\n",
    "    final_list = sorted(final)\n",
    "\n",
    "    print(f\"Writing to {OUTPUT} ...\")\n",
    "    with open(OUTPUT, \"w\", encoding=\"utf-8\") as f:\n",
    "        for line in final_list:\n",
    "            f.write(line + \"\\n\")\n",
    "    print(\"Done.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
